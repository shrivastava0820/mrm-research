{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "import numpy as np\n", "import seaborn as sns\n", "import matplotlib.pyplot as plt\n", "from sklearn.metrics import r2_score"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Load the data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df = pd.read_csv('ml1/CarPrice_Assignment.csv')\n", "df1=df.drop(['car_ID', 'CarName','fueltype', 'aspiration', 'doornumber',  'carbody', 'drivewheel', 'enginelocation', 'enginetype', 'cylindernumber', 'fuelsystem'], axis=1)\n", "# Drop 'car_ID' and 'CarName' because they are not useful features for prediction\n", "df = df.drop(['car_ID', 'CarName'], axis=1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Apply one-hot encoding to relevant categorical columns"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df_encoded = pd.get_dummies(df, columns=['fueltype', 'aspiration', 'doornumber', \n", "                                         'carbody', 'drivewheel', 'enginelocation', \n", "                                         'enginetype', 'cylindernumber', 'fuelsystem'])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Prepare the data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X = df_encoded['enginesize'].values.reshape(-1, 1)  # Example using 'enginesize' as feature\n", "y = df_encoded['price'].values  # Target variable"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Ensure X and y have the same number of samples"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(f\"Shape of X: {X.shape}\")\n", "print(f\"Shape of y: {y.shape}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Linear regression using gradient descent"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def linear_regression(X, y, learning_rate=0.00000001, iterations=9000):\n", "    w = 0  # Initialize slope\n", "    b = 0  # Initialize intercept\n", "    n = float(len(X))  # Number of data points\n", "    costs = []  # Store cost for each iteration\n", "    for i in range(iterations):\n", "        y_pred = w * X + b  # Predicted values\n", "        cost = (1/n) * sum((y - y_pred.flatten()) ** 2)  # Mean squared error (cost)\n", "        costs.append(cost)\n", "        D_w = (-2/n) * sum(X.flatten() * (y - y_pred.flatten()))  # Gradient for slope\n", "        D_b = (-2/n) * sum(y - y_pred.flatten())        # Gradient for intercept\n", "        w = w - learning_rate * D_w  # Update slope\n", "        b = b - learning_rate * D_b  # Update intercept\n", "    return w, b, costs"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Train the model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["w, b, costs = linear_regression(X, y)\n", "print(f\"Optimal slope (w): {np.round(w,2)}\")\n", "print(f\"Optimal intercept (b): {np.round(b,2)}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Make predictions"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_pred = (w * X + b).flatten()  # Flatten the predictions to match the shape of y"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Check if shapes match"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(f\"Shape of y_pred: {y_pred.shape}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Calculate R\u00c2\u00b2 score"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["r2 = r2_score(y, y_pred)  # Ensure y_pred and y have the same shape\n", "print(f\"R\u00c2\u00b2 score: {r2:.4f}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Plot the correlation matrix using Seaborn"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(10, 8))\n", "corr_matrix = df1.corr()\n", "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', square=True)\n", "plt.title('Correlation Matrix of Features')\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Plot cost vs. iteration graph"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(8, 6))\n", "plt.plot(range(len(costs)), costs, color='blue', label='Cost')\n", "plt.xlabel('Iterations')\n", "plt.ylabel('Cost (MSE)')\n", "plt.title('Cost vs Iterations')\n", "plt.legend()\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Convergence graph (cost difference between iterations)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["cost_diff = np.diff(costs)\n", "plt.figure(figsize=(8, 6))\n", "plt.plot(range(1, len(cost_diff) + 1), np.abs(cost_diff), color='green', label='Cost Difference')\n", "plt.xlabel('Iterations')\n", "plt.ylabel('Change in Cost')\n", "plt.title('Convergence of Gradient Descent')\n", "plt.legend()\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Plot regression line"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(8, 6))\n", "plt.scatter(X, y, color='blue', label='Actual data')\n", "plt.plot(X, y_pred, color='red', label='Regression line')\n", "plt.xlabel('Engine Size')\n", "plt.ylabel('Price')\n", "plt.title('Car Price Prediction using Linear Regression')\n", "plt.legend()\n", "plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}